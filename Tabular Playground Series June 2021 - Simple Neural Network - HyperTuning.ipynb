{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "structural-crown",
   "metadata": {},
   "source": [
    "Original Notebook: https://www.kaggle.com/pourchot/simple-neural-network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-moses",
   "metadata": {},
   "source": [
    "## Simple Neural Networks - Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-cooler",
   "metadata": {},
   "source": [
    "In this notebook, we will try to improve the performance of the Neural Network presented in the notebook https://www.kaggle.com/pourchot/simple-neural-network using Hyperparameters Tuning. The baseline model is identical from the one of the original notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tracked-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pycodestyle-magic to be compliant with PEP8 conventions\n",
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "russian-newspaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate pycodestyle for each cell\n",
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "rising-daily",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations,callbacks\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-presentation",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "limited-dinner",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "excited-postage",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['target'] = train['target'].str[-1]\n",
    "train = train.astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ancient-amber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200000, 75), (200000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.iloc[:, 1:-1].values\n",
    "y = train['target'].values\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "balanced-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hybrid-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 9\n",
    "y_train = keras.utils.to_categorical(\n",
    "    y_train-1, num_classes)\n",
    "y_val = keras.utils.to_categorical(\n",
    "    y_val-1, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-parliament",
   "metadata": {},
   "source": [
    "### Custom metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "medieval-letters",
   "metadata": {},
   "outputs": [],
   "source": [
    "cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "def custom_metric(y_true, y_pred):\n",
    "    y_pred = K.clip(y_pred, 1e-15, 1-1e-15)\n",
    "    loss = K.mean(cce(y_true, y_pred))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-holocaust",
   "metadata": {},
   "source": [
    "### Model with hyperparameters choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "hairy-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_custom_metric',\n",
    "    min_delta=1e-05,\n",
    "    patience=5,\n",
    "    verbose=0,\n",
    "    mode='min',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True)\n",
    "plateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_custom_metric',\n",
    "    factor=0.7,\n",
    "    patience=2,\n",
    "    verbose=0,\n",
    "    mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "significant-variable",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_model(hp):\n",
    "\n",
    "    conv_inputs = layers.Input(shape=(75))\n",
    "    # Embedding layers\n",
    "    hp_outdim = hp.Choice('output_dim', [7, 9, 11])\n",
    "    embed = layers.Embedding(\n",
    "        input_dim=354, \n",
    "        output_dim=hp_outdim,\n",
    "        embeddings_regularizer='l2')(conv_inputs)\n",
    "    # Convolution layers\n",
    "    embed = layers.Conv1D(\n",
    "        hp.Choice('filters', [8, 10, 12]),\n",
    "        1,\n",
    "        activation='relu')(embed)        \n",
    "    embed = layers.Flatten()(embed)\n",
    "    hidden = layers.Dropout(0.33)(embed)\n",
    "    # Residual blocks layers\n",
    "    hp_units_1 = hp.Choice('units1', [28, 32, 36])\n",
    "    hidden = tfa.layers.WeightNormalization(layers.Dense(\n",
    "        units=hp_units_1,\n",
    "        activation='selu',\n",
    "        kernel_initializer=\"lecun_normal\"))(hidden)\n",
    "    output = layers.Dropout(0.33)(layers.Concatenate()([embed, hidden]))\n",
    "    hp_units_2 = hp.Choice('units2', [28, 32, 36])\n",
    "    output = tfa.layers.WeightNormalization(\n",
    "    layers.Dense(\n",
    "        units=hp_units_2,\n",
    "        activation='relu',\n",
    "        kernel_initializer=\"he_normal\"))(output) \n",
    "    output = layers.Dropout(0.45)(layers.Concatenate()([embed, hidden, output]))\n",
    "    hp_units_3 = hp.Choice('units3', [28, 32, 36])\n",
    "    output = tfa.layers.WeightNormalization(layers.Dense(\n",
    "        units=hp_units_3, \n",
    "        activation='elu',\n",
    "        kernel_initializer=\"he_normal\"))(output)\n",
    "    # Final layer\n",
    "    conv_outputs = layers.Dense(\n",
    "        units=9, \n",
    "        activation='softmax')(output)\n",
    "    # Model instantiation\n",
    "    model = Model(conv_inputs,conv_outputs)\n",
    "    # Model compilation\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=2e-4),\n",
    "        metrics=custom_metric)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-scroll",
   "metadata": {},
   "source": [
    "### Keras Tuner Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "exposed-wisdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    conv_model,\n",
    "    objective=kt.Objective(\"val_custom_metric\", direction=\"min\"),\n",
    "    max_epochs=15,\n",
    "    directory='simple_neural_network_tuner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "inclusive-delhi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 5\n",
      "output_dim (Choice)\n",
      "{'default': 7, 'conditions': [], 'values': [7, 9, 11], 'ordered': True}\n",
      "filters (Choice)\n",
      "{'default': 8, 'conditions': [], 'values': [8, 10, 12], 'ordered': True}\n",
      "units1 (Choice)\n",
      "{'default': 28, 'conditions': [], 'values': [28, 32, 36], 'ordered': True}\n",
      "units2 (Choice)\n",
      "{'default': 28, 'conditions': [], 'values': [28, 32, 36], 'ordered': True}\n",
      "units3 (Choice)\n",
      "{'default': 28, 'conditions': [], 'values': [28, 32, 36], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "configured-visibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 06m 43s]\n",
      "val_custom_metric: 1.7432328462600708\n",
      "\n",
      "Best val_custom_metric So Far: 1.7426027059555054\n",
      "Total elapsed time: 01h 11m 33s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Wall time: 1h 11min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "BS = 64\n",
    "tuner.search(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=BS, \n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[es, plateau])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "accomplished-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "conditional-metabolism",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters\n",
      "-------------------------------\n",
      "Output dimension of Embedding Layer : 11\n",
      "Number of filters in Convolution Layer : 10\n",
      "Number of neurons in first Dense Layer : 32\n",
      "Number of neurons in second Dense Layer : 36\n",
      "Number of neurons in third Dense Layer : 32\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Hyperparameters\")\n",
    "print(\"-------------------------------\")\n",
    "print(f\"Output dimension of Embedding Layer : {best_hps.get('output_dim')}\")\n",
    "print(f\"Number of filters in Convolution Layer : {best_hps.get('filters')}\")\n",
    "print(f\"Number of neurons in first Dense Layer : {best_hps.get('units1')}\")\n",
    "print(f\"Number of neurons in second Dense Layer : {best_hps.get('units2')}\")\n",
    "print(f\"Number of neurons in third Dense Layer : {best_hps.get('units3')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-defeat",
   "metadata": {},
   "source": [
    "### Training the network with the best hyperparameters found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "julian-queue",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "targets = pd.get_dummies(train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "pending-spoke",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ====== TRAINING FOLD 0 =======\n",
      "\n",
      "\n",
      "-----Convolution model Training----\n",
      "\n",
      "\n",
      "FOLD 0 Score convolution model: 1.7481772336250172\n",
      "\n",
      "\n",
      " ====== TRAINING FOLD 1 =======\n",
      "\n",
      "\n",
      "-----Convolution model Training----\n",
      "\n",
      "\n",
      "FOLD 1 Score convolution model: 1.744758539665304\n",
      "\n",
      "\n",
      " ====== TRAINING FOLD 2 =======\n",
      "\n",
      "\n",
      "-----Convolution model Training----\n",
      "\n",
      "\n",
      "FOLD 2 Score convolution model: 1.74275841412805\n",
      "\n",
      "\n",
      " ====== TRAINING FOLD 3 =======\n",
      "\n",
      "\n",
      "-----Convolution model Training----\n",
      "\n",
      "\n",
      "FOLD 3 Score convolution model: 1.7472772572143003\n",
      "\n",
      "\n",
      " ====== TRAINING FOLD 4 =======\n",
      "\n",
      "\n",
      "-----Convolution model Training----\n",
      "\n",
      "\n",
      "FOLD 4 Score convolution model: 1.7342940068321302\n",
      "\n",
      "\n",
      " ====== TRAINING FOLD 5 =======\n",
      "\n",
      "\n",
      "-----Convolution model Training----\n",
      "\n",
      "\n",
      "FOLD 5 Score convolution model: 1.7391398285418749\n",
      "\n",
      "\n",
      " ====== TRAINING FOLD 6 =======\n",
      "\n",
      "\n",
      "-----Convolution model Training----\n",
      "\n",
      "\n",
      "FOLD 6 Score convolution model: 1.7458022547552363\n",
      "\n",
      "\n",
      " ====== TRAINING FOLD 7 =======\n",
      "\n",
      "\n",
      "-----Convolution model Training----\n",
      "\n",
      "\n",
      "FOLD 7 Score convolution model: 1.7324220458250492\n",
      "\n",
      "\n",
      " ====== TRAINING FOLD 8 =======\n",
      "\n",
      "\n",
      "-----Convolution model Training----\n",
      "\n",
      "\n",
      "FOLD 8 Score convolution model: 1.7399855792038144\n",
      "\n",
      "\n",
      " ====== TRAINING FOLD 9 =======\n",
      "\n",
      "\n",
      "-----Convolution model Training----\n",
      "\n",
      "\n",
      "FOLD 9 Score convolution model: 1.7417716698246077\n",
      "\n",
      "\n",
      " ====== TRAINING FOLD 10 =======\n",
      "\n",
      "\n",
      "-----Convolution model Training----\n",
      "\n",
      "\n",
      "FOLD 10 Score convolution model: 1.7385934493592008\n",
      "\n",
      "\n",
      " ====== TRAINING FOLD 11 =======\n",
      "\n",
      "\n",
      "-----Convolution model Training----\n",
      "\n",
      "\n",
      "FOLD 11 Score convolution model: 1.7433070147205145\n",
      "\n",
      "\n",
      " ====== TRAINING FOLD 12 =======\n",
      "\n",
      "\n",
      "-----Convolution model Training----\n",
      "\n",
      "\n",
      "FOLD 12 Score convolution model: 1.740225497066602\n",
      "\n",
      "\n",
      " ====== TRAINING FOLD 13 =======\n",
      "\n",
      "\n",
      "-----Convolution model Training----\n",
      "\n",
      "\n",
      "FOLD 13 Score convolution model: 1.7415414819598198\n",
      "\n",
      "\n",
      " ====== TRAINING FOLD 14 =======\n",
      "\n",
      "\n",
      "-----Convolution model Training----\n",
      "\n",
      "\n",
      "FOLD 14 Score convolution model: 1.743725114618987\n",
      "\n",
      "\n",
      " ====== TRAINING FOLD 15 =======\n",
      "\n",
      "\n",
      "-----Convolution model Training----\n",
      "\n",
      "\n",
      "FOLD 15 Score convolution model: 1.7474117520466448\n",
      "\n",
      "\n",
      " ====== TRAINING FOLD 16 =======\n",
      "\n",
      "\n",
      "-----Convolution model Training----\n",
      "\n",
      "\n",
      "FOLD 16 Score convolution model: 1.739519080099836\n",
      "\n",
      "\n",
      " ====== TRAINING FOLD 17 =======\n",
      "\n",
      "\n",
      "-----Convolution model Training----\n",
      "\n",
      "\n",
      "FOLD 17 Score convolution model: 1.7399100909661502\n",
      "\n",
      "\n",
      " ====== TRAINING FOLD 18 =======\n",
      "\n",
      "\n",
      "-----Convolution model Training----\n",
      "\n",
      "\n",
      "FOLD 18 Score convolution model: 1.7404785444352775\n",
      "\n",
      "\n",
      " ====== TRAINING FOLD 19 =======\n",
      "\n",
      "\n",
      "-----Convolution model Training----\n",
      "\n",
      "\n",
      "FOLD 19 Score convolution model: 1.7426474385112525\n",
      "\n",
      "\n",
      "=== FINAL SCORE CONVOLUTION MODEL : 1.7416873254504561===\n",
      "\n",
      "Wall time: 1h 10min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "oof_NN = np.zeros((train.shape[0], 9))\n",
    "pred_NN = np.zeros((test.shape[0], 9))\n",
    "N_FOLDS = 20\n",
    "SEED = 42\n",
    "EPOCH = 50\n",
    "skf = StratifiedKFold(\n",
    "    n_splits=N_FOLDS, \n",
    "    shuffle=True,\n",
    "    random_state=SEED)\n",
    "for fold, (tr_idx, ts_idx) in enumerate(skf.split(train, train.iloc[:, -1])):\n",
    "    print(f\"\\n ====== TRAINING FOLD {fold} =======\\n\")\n",
    "    X_train = train.iloc[:, 1:-1].iloc[tr_idx]\n",
    "    y_train = targets.iloc[tr_idx]\n",
    "    X_test = train.iloc[:, 1:-1].iloc[ts_idx]\n",
    "    y_test = targets.iloc[ts_idx]\n",
    "    K.clear_session()\n",
    "    # NN CONV MODEL training\n",
    "    print(\"\\n-----Convolution model Training----\\n\")\n",
    "    # Build the model with the optimal hyperparameters\n",
    "    model_conv = tuner.hypermodel.build(best_hps)\n",
    "    model_conv.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=256,\n",
    "        epochs=EPOCH,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=[es, plateau],\n",
    "        verbose=0)\n",
    "    # Convolution Model prediction\n",
    "    pred = model_conv.predict(X_test)\n",
    "    oof_NN[ts_idx] += pred\n",
    "    score_NN = log_loss(y_test, pred)\n",
    "    print(f\"\\nFOLD {fold} Score convolution model: {score_NN}\\n\")\n",
    "    pred_NN += model_conv.predict(test.iloc[:, 1:])/N_FOLDS\n",
    "score = log_loss(targets, oof_NN)\n",
    "print(f\"\\n=== FINAL SCORE CONVOLUTION MODEL : {score}===\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "loose-insertion",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_embedding = pred_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "automatic-simon",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"sample_submission.csv\")\n",
    "for i in range(9):\n",
    "    submission[f'Class_{i+1}'] = pred_embedding[:, i]\n",
    "submission.to_csv(\"Purchot_tuned_neural_network.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-lodge",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oc-p8-env",
   "language": "python",
   "name": "oc-p8-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
